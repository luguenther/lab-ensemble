{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling and engineering completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Drop PassengerId and Name columns\n",
    "df.drop(columns=['PassengerId', 'Name'], inplace=True)\n",
    "\n",
    "# Transform Cabin to contain only the first letter (deck category)\n",
    "df['Cabin'] = df['Cabin'].astype(str).str[0]\n",
    "\n",
    "# Convert categorical variables to dummies\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['Transported'])\n",
    "y = df['Transported']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Fill missing numerical values with median\n",
    "X_train = X_train.fillna(X_train.median())\n",
    "X_test = X_test.fillna(X_test.median())\n",
    "\n",
    "# Feature Scaling (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling and engineering completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['Transported'])  # Features (independent variables)\n",
    "y = df['Transported']  # Target variable\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Print shapes to verify split\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(\"Train-Test Split completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.7941\n",
      "Pasting Accuracy: 0.7412\n",
      "\n",
      "Bagging Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.81      0.80       863\n",
      "        True       0.80      0.78      0.79       876\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.79      0.79      0.79      1739\n",
      "weighted avg       0.79      0.79      0.79      1739\n",
      "\n",
      "\n",
      "Pasting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.71      0.73       863\n",
      "        True       0.73      0.77      0.75       876\n",
      "\n",
      "    accuracy                           0.74      1739\n",
      "   macro avg       0.74      0.74      0.74      1739\n",
      "weighted avg       0.74      0.74      0.74      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize base estimator (Decision Tree)\n",
    "base_estimator = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Bagging Classifier (Updated Syntax)\n",
    "bagging_clf = BaggingClassifier(estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "bagging_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_bagging = bagging_clf.predict(X_test_scaled)\n",
    "\n",
    "# Pasting Classifier (Bagging with bootstrap=False, Updated Syntax)\n",
    "pasting_clf = BaggingClassifier(estimator=base_estimator, n_estimators=50, bootstrap=False, random_state=42)\n",
    "pasting_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_pasting = pasting_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "accuracy_pasting = accuracy_score(y_test, y_pred_pasting)\n",
    "class_report_bagging = classification_report(y_test, y_pred_bagging)\n",
    "class_report_pasting = classification_report(y_test, y_pred_pasting)\n",
    "\n",
    "# Print results\n",
    "print(f\"Bagging Accuracy: {accuracy_bagging:.4f}\")\n",
    "print(f\"Pasting Accuracy: {accuracy_pasting:.4f}\")\n",
    "print(\"\\nBagging Classification Report:\\n\", class_report_bagging)\n",
    "print(\"\\nPasting Classification Report:\\n\", class_report_pasting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7947\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.82      0.80       863\n",
      "        True       0.81      0.77      0.79       876\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.80      0.79      0.79      1739\n",
      "weighted avg       0.80      0.79      0.79      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Random Forest model\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = random_forest_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "class_report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Print results\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", class_report_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.8033\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.77      0.80       863\n",
      "        True       0.79      0.84      0.81       876\n",
      "\n",
      "    accuracy                           0.80      1739\n",
      "   macro avg       0.80      0.80      0.80      1739\n",
      "weighted avg       0.80      0.80      0.80      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Gradient Boosting model\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "class_report_gb = classification_report(y_test, y_pred_gb)\n",
    "\n",
    "# Print results\n",
    "print(f\"Gradient Boosting Accuracy: {accuracy_gb:.4f}\")\n",
    "print(\"\\nGradient Boosting Classification Report:\\n\", class_report_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Boosting Accuracy: 0.7752\n",
      "\n",
      "Adaptive Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.81      0.78       863\n",
      "        True       0.80      0.74      0.77       876\n",
      "\n",
      "    accuracy                           0.78      1739\n",
      "   macro avg       0.78      0.78      0.78      1739\n",
      "weighted avg       0.78      0.78      0.77      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize AdaBoost model with default base estimator (Decision Stump)\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "ada_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ada = ada_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "class_report_ada = classification_report(y_test, y_pred_ada)\n",
    "\n",
    "# Print results\n",
    "print(f\"Adaptive Boosting Accuracy: {accuracy_ada:.4f}\")\n",
    "print(\"\\nAdaptive Boosting Classification Report:\\n\", class_report_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the accuracy and classification reports, Gradient Boostin performed the best among all models.\n",
    "#Why is Gradient Boosting the Best?\n",
    "\n",
    "# Highest Accuracy (80.33%)\n",
    "# It outperforms all other models by achieving the best accuracy.\n",
    "# Balanced Precision & Recall\n",
    "# Both precision and recall are well-balanced, ensuring the model makes fewer false positives and false negatives.\n",
    "# False (not transported) recall: 77%\n",
    "# True (transported) recall: 84% (better than other models)\n",
    "# Handles Complex Relationships Better\n",
    "# Unlike Bagging or Random Forest, Gradient Boosting sequentially improves each tree, learning from previous mistakes.\n",
    "# Improvement Over Adaptive Boosting\n",
    "# While Adaptive Boosting (AdaBoost) achieved 77.52% accuracy, its recall for True class was only 74%, meaning it misclassified more transported passengers.\n",
    "Gradient Boosting improved this to 84%, leading to a better F1-score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
